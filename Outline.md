## This is an outline for the CSCI-3395 Big Data final project

# Dataset Background
The dataset I chose to use for this project contains crime related data from 2001 to 2017 in Chicago, Illinois. The data came from [kaggle](https://www.kaggle.com/currie32/crimes-in-chicago), and was originally from the Chicago Citizen Law Enforcement Analysis and Reporting system. The data points include case numbers, dates, type of crimes, location descriptions, whether an arrest was made, some location coordinates, and descriptions of the crime. Some of the location information has been slightly changed to provide anonymity for the crimes themselves. There are also no data points for murders where data exists for each victim.

# Questions and Motivation
In looking at this data set, I had a lot of small questions first. How many crimes were there total? 7,941,286 crimes. How many crimes contained accurate location data? 7,835,457. Then I started to think what I could do with the techniques we had learned in class. My first thought was could we predict crime? Given historical data, could we accurately predict how much crime would happen in a certain location at a certain time? Given all of the information about a crime except for its type, can we classify it? Analysis like this might be able to actually simulate crime and provide accurate simulations for professionals to use in the crime-fighting business. Another question I thought of was can we predict whether an arrest was made? This interests me because it would reveal the most important factors in which it becomes possible to make arrests.

# Analysis
The first question I wanted to answer was what are the top 5 most common crimes in Chicago? They are Larceny, Simple Battery, Vandalism, Drug Abuse, and Misc. Non-Indexed Crime in that order. The steepest cliffs are between Larceny and Simple Battery (1,614,657 and 1,224,442) and between Drug Abuse and Misc. Non-Indexed Crime, (807,845 and 467,136). I was curious about robbery, homicide, and prostitution specifically because I thought those crimes would be the most clustered, so I made [prostitution](plots/prostitution.png), [homicide](plots/homicide.png), and [robbery](plots/robbery.png) plots. The next question I wanted to answer was if we could we predict crime? That question seems quite broad, and when I thought more about it, we could predict crime in a location based on how much crime had happened in that location in the past. So then I thought it would be more interesting to pursue whether or not we could accurately predict if an arrest was made.I decided to use a RandomForestClassifier to do this. The first step was to assemble all of my data into a data frame, effectively concatenating all of my files. Then I had to decide which features to actually use. Some of the data would not make sense to use in classifying whether an arrest was made. I decided to use the date (year, month, and day separately), and the location description, the community area code, the ward, and the type of the crime according to the FBI's coding scheme. Using a RandomForestClassifier with 20 trees and a maximum depth of 5, I was able to get results of 82% classification. There were two questions I had about the classifications, how was it failing in that 18%? False negatives or false positives? And also what features were the most important in classifying? The model was heavily favoring false negatives, those were predicted 243,672 times and false positives only happened 3,413 times. I then made [these](plots/Arrests.png) [plots](plots/NoArrests.png) to look at the types of crimes that arrests were made for. Looking more into the data, there are 2,224,932 crimes where arrests were made, and 5,610,525 crimes where arrests were not made. This makes sense that the model would then be more likely to predict no arrest. The most important feature was the FBI code in classifying the data. The second most important was the description of the location in which the crime occurred. The next most important was the ward in which the crime occurred. The next thing I wanted to do was to create a [deep feed forward](crimes-in-chicago/DeepFeedForward.jpg) neural network to predict the type of the top 5 crimes. I used 3 hidden layers, each with 50 inputs. I had to concatenate the data files into one plain text file, as I did not use Spark for the deep learning analysis. I also filtered out all of the other data that was not a top 5 crime. Training and testing on a smaller subset of the data, I was able to get an accuracy rate of 34%. The model rarely predicted that a crime was a Misc. Non-Indexed Crime. The majority of the predictions it made were for larceny and drug abuse. 
